<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>【计量经济学（四）】多元回归分析：估计 | Toby_'s   Blog</title><meta name="author" content="Toby_"><meta name="copyright" content="Toby_"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="多元回归模型 $$ y&#x3D;\beta_0+\beta_1x_1+\beta_2x_2+…+\beta_kx_k+u $$ Example： 可以在模型中加入更多的解释变量： $$ wage&#x3D;\beta_0+\beta_1educ+\beta_2{exper}+u $$ 更加灵活的方程形式： 家庭收入（inc）和消费（cons）的关系： $$ cons&#x3D;\beta_0+\beta_1inc+\beta">
<meta property="og:type" content="article">
<meta property="og:title" content="【计量经济学（四）】多元回归分析：估计">
<meta property="og:url" content="http://example.com/2023/10/07/%E8%AE%A1%E9%87%8F%E7%BB%8F%E6%B5%8E%E5%AD%A64/index.html">
<meta property="og:site_name" content="Toby_&#39;s   Blog">
<meta property="og:description" content="多元回归模型 $$ y&#x3D;\beta_0+\beta_1x_1+\beta_2x_2+…+\beta_kx_k+u $$ Example： 可以在模型中加入更多的解释变量： $$ wage&#x3D;\beta_0+\beta_1educ+\beta_2{exper}+u $$ 更加灵活的方程形式： 家庭收入（inc）和消费（cons）的关系： $$ cons&#x3D;\beta_0+\beta_1inc+\beta">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s2.loli.net/2023/10/13/d18EbiWQkAPCpIB.webp">
<meta property="article:published_time" content="2023-10-07T02:29:06.859Z">
<meta property="article:modified_time" content="2024-01-15T09:41:28.834Z">
<meta property="article:author" content="Toby_">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2023/10/13/d18EbiWQkAPCpIB.webp"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2023/10/07/%E8%AE%A1%E9%87%8F%E7%BB%8F%E6%B5%8E%E5%AD%A64/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '【计量经济学（四）】多元回归分析：估计',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-01-15 17:41:28'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="https://src.ffing.cn/hexo/css/nav_menu.css"><script defer src="https://src.ffing.cn/hexo/js/switchDarkMode.js"></script><script defer src="/js/nav_menu.js"></script><meta name="generator" content="Hexo 6.3.0"><link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head><body><script>window.paceOptions = {
  restartOnPushState: false
}

document.addEventListener('pjax:send', () => {
  Pace.restart()
})
</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pace-js/themes/blue/pace-theme-minimal.min.css"/><script src="https://cdn.jsdelivr.net/npm/pace-js/pace.min.js"></script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">31</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/gallery/"><i class="fa-fw fas fa-tags"></i><span> Gallery</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://s2.loli.net/2023/10/13/d18EbiWQkAPCpIB.webp')"><nav id="nav"><span id="blog_name"><div class="back-home-button" tabindex="-1"><i class="back-home-button-icon fas fa-grip-vertical"></i><div class="back-menu-list-groups"></div></div><a id="site-name" href="/"><div class="title">Toby_'s   Blog</div><i class="fa-solid fa-house"></i></a></span><div class="mask-name-container"><center id="name-container"><a id="page-name" href="javascript:btf.scrollToDest(0, 500)">“分无义，乐真谛”</a></center></div><div id="weather"></div><div id="tp-weather-widget"></div> <div id="menus"><div class="nav-button" id="darkmode_navswitch"><a class="darkmode_switchbutton" type="button" title="浅色和深色模式转换" onclick="switchDarkMode()"><i class="fas fa-adjust"></i></a></div><div class="nav-button" id="nav-totop"><a class="totopbtn"><i class="fas fa-arrow-up"></i><span id="percent" onclick="btf.scrollToDest(0,500)">0</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/gallery/"><i class="fa-fw fas fa-tags"></i><span> Gallery</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">【计量经济学（四）】多元回归分析：估计</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-10-07T02:29:06.859Z" title="发表于 2023-10-07 10:29:06">2023-10-07</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-01-15T09:41:28.834Z" title="更新于 2024-01-15 17:41:28">2024-01-15</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%A1%E9%87%8F%E7%BB%8F%E6%B5%8E%E5%AD%A6/">计量经济学</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">3.2k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>13分钟</span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h3 id="多元回归模型">多元回归模型</h3>
<p>$$<br>
y=\beta_0+\beta_1x_1+\beta_2x_2+…+\beta_kx_k+u<br>
$$</p>
<h3 id="Example：">Example：</h3>
<p>可以在模型中加入更多的解释变量：<br>
$$<br>
wage=\beta_0+\beta_1educ+\beta_2{exper}+u<br>
$$<br>
更加灵活的方程形式：</p>
<p>家庭收入（inc）和消费（cons）的关系：<br>
$$<br>
cons=\beta_0+\beta_1inc+\beta_2inc^2+u<br>
$$</p>
<h3 id="多元回归方程的推导">多元回归方程的推导</h3>
<p>总体方程：<br>
$$<br>
y_i=\beta_0+\beta_1x_{i1}+\beta_2x_{i2}+…+\beta_kx_{ik}+u_i<br>
$$<br>
拟合值：<br>
$$<br>
\hat{y_i}=\hat{\beta_0}+\hat{\beta_1}x_{i1}+\hat{\beta_2}x_{i2}+…+\hat{\beta_k}x_{ik}<br>
$$<br>
残差：<br>
$$<br>
\hat{u_i}=y_i-\hat{y_i}=y_i-\hat{\beta_0}-\hat{\beta_1}x_{i1}-\hat{\beta_2}x_{i2}-…-\hat{\beta_k}x_{ik}<br>
$$<br>
最小化残差平方和：<br>
$$<br>
min\sum_{i=1}^n \hat{u_i}^2=min\sum_{i=1}^n(y_i-\hat{\beta_0}-\hat{\beta_1}x_{i1}-\hat{\beta_2}x_{i2}-…-\hat{\beta_k}x_{ik})^2<br>
$$<br>
<strong>一阶条件</strong>（分别对$\beta_i$求导）：<br>
$$<br>
\frac{\partial \sum_{i=1}^n \hat{u_i}^2}{\partial \hat{\beta_0}}=\sum_{i=1}^n-2(y_i-\hat{\beta_0}-\hat{\beta_1}x_{i1}-\hat{\beta_2}x_{i2}-…-\hat{\beta_k}x_{ik}) =\sum_{i=1}^n \hat{u_i}=0<br>
$$</p>
<p>$$<br>
\frac{\partial \sum_{i=1}^n \hat{u_i}^2}{\partial \hat{\beta_1}}=\sum_{i=1}^n-2x_{i1}(y_i-\hat{\beta_0}-\hat{\beta_1}x_{i1}-\hat{\beta_2}x_{i2}-…-\hat{\beta_k}x_{ik}) =\sum_{i=1}^n x_{i1}\hat{u_i}=0<br>
$$</p>
<p>同理对于$ \forall k&gt;0$：<br>
$$<br>
\sum_{i=1}^n x_{ik}\hat{u_i}=0<br>
$$<br>
k+1个方程求解k+1个变量。</p>
<h3 id="数值特征：">数值特征：</h3>
<h4 id="样本均值点在回归线上">样本均值点在回归线上</h4>
<p>$$<br>
\bar{y}=\hat{\beta_0}+\hat{\beta_1}\bar{x}_1+\hat{\beta_2}\bar{x}_2+…+\hat{\beta_k}\bar{x}_k<br>
$$</p>
<p>证明：<br>
$$<br>
\sum_{i=1}^n\hat{u_i}=\sum_{i=1}^n(y_i-\hat{y_i})=0 \<br>
=&gt; \ \ \bar{y}=\bar{\hat{y}}<br>
$$<br>
再对n个估计式累加再除以n，易得证。</p>
<h4 id="每个自变量和OLS残差之间的样本协方差为零">每个自变量和OLS残差之间的样本协方差为零</h4>
<p>样本协方差为：<br>
$$<br>
=\frac{1}{n-1}(\sum_{i=1}^n(x_{i1}-\bar{x})(\hat{u_i}-\bar{\hat{u}}))  \<br>
=\frac{1}{n-1}(\sum_{i=1}^n x_{i1}\hat{u_i}-\sum_{i=1}^n x_{i1}\bar{\hat{u}}-\sum_{i=1}^n \bar{x}\hat{u_i}+\sum_{i=1}^n \bar{x}\bar{\hat{u}}) =0<br>
$$</p>
<h4 id="高级计量结果">*高级计量结果</h4>
<p>$$<br>
\hat{\beta}=(X’X)^{-1}X’y<br>
$$</p>
<h3 id="对多元回归排除其他变量的解释">对多元回归排除其他变量的解释</h3>
<p>字面上来说，$\beta_i$是保持其他变量不变时，$x_i$变化对$y$的影响。而事实上，自变量之间存在或多或少的关联，如$x_1$的变动会导致$x_2$的变动，而$x_2$的变动又会导致$y$的变动。但我们在衡量$x_1$对$y$的影响(即$\beta_1$)时仅仅考虑$x_1$对$y$的直接影响，通过其他变量间接传导的影响不在考虑之内。</p>
<p>正因如此，多元回归的系数结果通常不等于一元回归，因为多元回归中自变量大概率存在关联性，而多元回归的过程中自动排除了相关变量间接传导的影响。</p>
<p>$\hat{\beta_1}$可以写成另外一个形式：<br>
$$<br>
\hat{\beta_1}=\frac{\sum_{i=1}^n\hat{r}<em>{i1}y_i}{\sum</em>{i=1}^n\hat{r}_{i1}^2}<br>
$$<br>
其中，残差$r$来自$x_1$对$x_2,x_3,…,x_k$的回归。</p>
<h5 id="证明：">证明：</h5>
<p>已知 $x_{i1}=\hat{x}<em>{i1}+\hat{r}</em>{i1}$，代入原回归的一阶条件得：<br>
$$<br>
\sum_{i=1}^n (\hat{x}<em>{i1}+\hat{r}</em>{i1})(y_i-\hat{\beta}<em>0-\hat\beta_1x</em>{i1}-…-\hat{\beta}<em>kx</em>{ik})=0<br>
$$<br>
而$\hat{x}<em>{i1}$是$x</em>{i2},…,x_{ik}$的线性函数，故 $\sum_{i=1}^n\hat{x}<em>{i1}\hat{u}<em>i=0$，于是：<br>
$$<br>
\sum</em>{i=1}^n \hat{r}</em>{i1}(y_i-\hat{\beta}<em>0-\hat\beta_1x</em>{i1}-…-\hat{\beta}<em>kx</em>{ik})=0<br>
$$</p>
<p>而 $\hat{r}<em>{i1}$是残差，故$\sum</em>{i=1}^n x_{ij}\hat{r}<em>{i1}=0$，于是：<br>
$$<br>
\sum</em>{i=1}^n \hat{r}<em>{i1}(y_i-\hat\beta_1x</em>{i1})=0 \<br>
\sum_{i=1}^n \hat{r}<em>{i1}(y_i-\hat\beta_1(\hat{x}</em>{i1}-\hat{r}<em>{i1}))=0 \<br>
\sum</em>{i=1}^n \hat{r}<em>{i1}(y_i-\hat\beta_1\hat{r}</em>{i1})=0<br>
$$<br>
最终得到：<br>
$$<br>
\hat{\beta_1}=\frac{\sum_{i=1}^n\hat{r}<em>{i1}y_i}{\sum</em>{i=1}^n\hat{r}_{i1}^2}<br>
$$</p>
<h5 id="理解">理解:</h5>
<p>因为残差$\hat{r}<em>{i1}$是$x</em>{i1}$中与剩余$x_{j1}$不相关的部分，故$\hat{\beta}_1$度量了排除其他自变量影响后$y$与$x_1$的关系。这个结果成为<strong>弗里施-沃定理</strong>（$Frish-Waugh \ theorem$），这种回归方式称为分块回归或偏回归。</p>
<h3 id="拟合优度-R-2">拟合优度$R^2$</h3>
<p>$R^2$等于$y_i$实际值与其拟合值$\hat{y_i}$的相关系数的平方<br>
$$<br>
R^2=(corr(y_i,\hat{y_i}))^2=\frac{(\sum_{i=1}^n(y_i-\bar{y})(\hat{y_i}-\bar{\hat{y}}))^2}{(\sum_{i=1}^n(y_i-\bar{y})^2)(\sum_{i=1}^n(\hat{y_i}-\bar{\hat{y}})^2)}<br>
$$<br>
证明：</p>
<img src="https://s2.loli.net/2023/11/11/nSyOZRCLGwPiDfg.png" style="zoom: 67%;" />
<h2 id="OLS-估计量的期望值">$OLS$估计量的期望值</h2>
<h3 id="经典假设条件">经典假设条件</h3>
<h4 id="Assumption-MLR-1-线性于参数">Assumption MLR.1 (线性于参数)</h4>
<p>$$<br>
y=\beta_0+\beta_1x_1+\beta_2x_2+…+\beta_kx_k+u<br>
$$</p>
<p>这是对<strong>总体模型</strong>或<strong>真实模型</strong>的规范表述</p>
<h4 id="Assumption-MLR-2-随机抽样">Assumption MLR.2 (随机抽样)</h4>
<p>$$<br>
{ (x_{i1},x_{i2},…,x_{ik},y_i): i = 1…n  }<br>
$$</p>
<p>$$<br>
y_i=\beta_0+\beta_1x_{i1}+\beta_2x_{i2}+…+\beta_kx_{ik}+u_i<br>
$$</p>
<p>该假设控制了单个样本不受其它样本影响。</p>
<h4 id="Assumption-MLR-3-No-perfect-collinearity不存在完全共线性">Assumption MLR.3  (No perfect collinearity不存在完全共线性)</h4>
<p><strong>在样本中，没有一个自变量是常数，自变量之间也不存在严格的线性关系（可以有相关性）。</strong></p>
<p>从矩阵来看，如果存在线性关系，就不满秩了，也就没有逆矩阵了。</p>
<p>该假设可以保证存在<strong>唯一</strong>的$OLS$估计值</p>
<h4 id="Assumption-MLR-4-条件均值为零">Assumption MLR.4(条件均值为零)</h4>
<p>$$<br>
E(u_i|x_{i1},x_{i2},…,x_{ik})=0<br>
$$</p>
<p>简单来说，误差项和解释变量是<strong>不相关</strong>的。</p>
<p>具体意味着，影响$y$的其他因素总体上与$x_{i1},x_{i2},…,x_{ik}$不相关。</p>
<h3 id="定理3-1-无偏性">定理3.1 无偏性</h3>
<p>由$MLR.1-MLR.4$可以推导出：<br>
$$<br>
E(\hat{\beta_j})=\beta_j<br>
$$</p>
<h5 id="初等代数证明：">初等代数证明：</h5>
<p>我们已知：<br>
$$<br>
\hat{\beta_1}=\frac{\sum_{i=1}^n\hat{r}<em>{i1}y_i}{\sum</em>{i=1}^n\hat{r}<em>{i1}^2}<br>
$$<br>
将总体方程代入：<br>
$$<br>
y_i=\beta_0+\beta_1x</em>{i1}+\beta_2x_{i2}+…+\beta_kx_{ik}+u_i<br>
$$<br>
可得：<br>
$$<br>
\hat{\beta_1}=\beta_1+\frac{\sum_{i=1}^n\hat{r}<em>{i1}u_i}{\sum</em>{i=1}^n\hat{r}<em>{i1}^2}<br>
$$<br>
考虑到$\hat{r}</em>{i1}$只是样本自变量的函数，于是：<br>
$$<br>
E(\hat{\beta}<em>1|X)=\beta_1+\frac{\sum</em>{i=1}^n\hat{r}<em>{i1}E(u_i|X)}{\sum</em>{i=1}^n\hat{r}_{i1}^2}=0<br>
$$<br>
得证。</p>
<h5 id="矩阵证明：">矩阵证明：</h5>
<p>​	暂时略，后续补充。</p>
<p>实证研究中，有些情况可能会影响我们获得无偏估计值，如：</p>
<h3 id="哪些情况会影响我们获得无偏估计值？">哪些情况会影响我们获得无偏估计值？</h3>
<h4 id="遗漏变量：">遗漏变量：</h4>
<p>假设真实世界中：<br>
$$<br>
y=\beta_0+\beta_1x_1+\beta_2x_2+u<br>
$$<br>
但由于种种因素，导致我们忽略了$x_2$的存在，仅以为：<br>
$$<br>
y=\alpha_0+\alpha_1x_1+w<br>
$$<br>
$x_2$某种程度上变成了$w$的一部分。</p>
<p>而$x_2$与$x_1$之间存在关系:<br>
$$<br>
x_2=\delta_0+\delta_1x_1+v<br>
$$<br>
则：<br>
$$<br>
y=\beta_0+\beta_1x_1+\beta_2(\delta_0+\delta_1x_1+v)+u \<br>
=(\beta_0+\beta_2\delta_0)+(\beta_1+\beta_2\delta_1)x_1+(\beta_2v+u)<br>
$$<br>
这导致我们的估计值为：<br>
$$<br>
\alpha_1=\beta_1+\beta_2\delta_1<br>
$$<br>
与真实结果产生了偏差。而估计值由两部分构成，一部分是$x_1$本身的影响，另一部分是$x_1$通过影响$x_2$间接对$y$产生的影响。</p>
<p>如果结果不产生偏差，则说明：<br>
$$<br>
\delta_1 =0  \ \ \ 或  \ \ \  \beta_2=0<br>
$$<br>
即，要么样本中$x_1$和$x_2$不相关，要么$x_2$本身对$y$没有影响。</p>
<p>在回归模型中加入自变量的过程某种程度上可以理解为不断<strong>控制变量</strong>的过程，例如，在衡量$x_1$的影响时，模型自动排除了$x_2,x_3…x_n$的影响。</p>
<p>如果$x_2$只与$y$有关而与$x_1$无关，则不会的$\beta_1$的无偏性造成影响，只是由于遗漏$x_2$导致误差项中的$\sigma^2$提升，进而会提高$Var(\beta_1)$。（当然$R_j^2$也会有所变化，但因为$x_2$与$x_1$无关，所以$R_j^2$变化不大）因此，一般认为$x_2$也要加入回归。</p>
<h3 id="OLS-统计量的方差">$OLS$统计量的方差</h3>
<h4 id="Assumption-MLR-5-同方差性">Assumption MLR.5 (同方差性)</h4>
<p>$$<br>
Var(u_i|x_{i1},x_{i2},…,x_{ik}) = \sigma^2<br>
$$</p>
<p>给定任意解释变量值，误差$u$都具有相同的方差。</p>
<p>由$MLR.5$：<br>
$$<br>
Var(y|X)=\sigma^2<br>
$$<br>
即给定$x$，$y$的方差不取决于自变量的值。</p>
<h3 id="定理3-2-OLS-斜率估计量的抽样方差">定理3.2  $OLS$斜率估计量的抽样方差</h3>
<p>根据假设$MLR.1-MLR.5$（<strong>高斯-马尔科夫假定</strong>），可以推导到：<br>
$$<br>
Var(\hat{\beta_j})=\frac{\sigma^2}{SST_j(1-R_j^2)} \ \  \ \ \ ,j=1,2…k<br>
$$<br>
其中：<br>
$$<br>
SST_j=\sum_{i=1}^n(x_{ij}-\bar{x}_j)^2<br>
$$<br>
$SST_j$用来衡量自变量$x_j$的样本波动性</p>
<p>$R_j^2$是一个拟合优度，来自一个回归模型，其中因变量为$x_j$，自变量是其他解释变量（包括常数项），其本质上是在衡量其他$x$与$x_j$的相关程度。<br>
$$<br>
x_j=\alpha_0+\alpha_1x_1+…+\alpha_{j-1}x_{j-1}+\alpha_{j+1}x_{j+1}+…+\alpha_kx_k+v<br>
$$</p>
<h5 id="证明">证明</h5>
<p>$$<br>
Var(\hat{\beta_1})=Var(\frac{\sum_{i=1}^n\hat{r}<em>{i1}y_i}{\sum</em>{i=1}^n\hat{r}<em>{i1}^2}) =\frac{\sum</em>{i=1}^n\hat{r}<em>{i1}^2Var(u_i|X)}{(\sum</em>{i=1}^n\hat{r}<em>{i1}^2)^2}<br>
=\frac{\sum</em>{i=1}^n\hat{r}<em>{i1}^2\sigma^2}{(\sum</em>{i=1}^n\hat{r}<em>{i1}^2)^2}<br>
=\frac{\sigma^2}{\sum</em>{i=1}^n\hat{r}_{i1}^2}<br>
$$</p>
<p>因为$\sum_{i=1}^n\hat{r}^2_{i1}$是$x_1$对$x_2,…,x_k$回归的残差平方和，故：<br>
$$<br>
\sum_{i=1}^n\hat{r}^2_{i1} =SST_1(1-R_1^2)<br>
$$<br>
得证。</p>
<p>从上述公式来看，$Var(\hat{\beta_j})$受三个部分影响。</p>
<ul>
<li>
<p>$\sigma^2$越大，方差中“噪声”越大，导致方差越大</p>
</li>
<li>
<p>$x_j$的总样本波动越大，跨度越大，结果越准确，$\beta$的方差就越小</p>
</li>
<li>
<p>如果$R^2$很大，代表着相关性很大，代表着很多信息由于相关性而产生了重叠，“有用”的信息越少，方差越大。</p>
</li>
</ul>
<h3 id="多重共线性">多重共线性</h3>
<p>两个或多个自变量之间高度（但不完全）相关被称为<strong>多重共线性</strong>$(multicollinearity)$</p>
<h4 id="解决多重共线性的方法">解决多重共线性的方法</h4>
<p>1、把一些变量加总起来（如各项支出）</p>
<p>2、把某些变量剔除（装看不见嘿嘿），尽管可能会导致变量遗漏问题。</p>
<p>3、构建<strong>方差膨胀因子</strong>（$variance\ inflation\ factors$）<br>
$$<br>
VIF_j=\frac{1}{1-R_j^2}<br>
$$<br>
常见的指标是 $VIF$ 不能大于10</p>
<h3 id="误设模型中的方差">误设模型中的方差</h3>
<p>回归模型中是否添加某特定变量的判断标准。</p>
<p>真实的回归模型：<br>
$$<br>
y=\beta_0+\beta_1x_1+\beta_2x_2+u<br>
$$<br>
回归模型1：<br>
$$<br>
\hat{y}=\hat{\beta_0}+\hat{\beta_1}x_1+\hat{\beta_2}x_2<br>
$$<br>
回归模型2：<br>
$$<br>
\tilde{y}=\tilde{\beta_0}+\tilde{\beta_1}x_1<br>
$$<br>
通过计算可得：<br>
$$<br>
Var(\hat{\beta_1})=\frac{\sigma^2}{SST_1(1-R_1^2)}<br>
$$</p>
<p>$$<br>
Var(\tilde{\beta_1})=\frac{\sigma^2}{SST_1}<br>
$$</p>
<p>可以看到，$Var(\hat{\beta_1})&gt;Var(\tilde{\beta_1})$（其实不对，因为两个式子中的$\sigma$不一样），可见增加自变量会增加估计量的去方差（至少不会减少）。</p>
<p>考虑如下情况：</p>
<p>若 $\beta_2=0$ ,则：<br>
$$<br>
E(\hat{\beta_1})=\beta_1 \ \ \ E(\tilde{\beta_1})=\beta_1 \<br>
Var(\hat{\beta_1})&gt;Var(\tilde{\beta_1})<br>
$$<br>
这告诉我们<strong>不要把无关变量放进模型</strong>，无关变量只会加剧共线性问题。</p>
<p>若 $\beta_2 \not=0$ ,则：<br>
$$<br>
E(\hat{\beta_1})=\beta_1 \ \ \ E(\tilde{\beta_1})\not=\beta_1 \<br>
Var(\hat{\beta_1})&gt;Var(\tilde{\beta_1})<br>
$$<br>
这时候就需要进行<strong>取舍</strong>（$trade\ off$），经济学中一般认为无偏性更加重要一点</p>
<h3 id="估计误差项的方差">估计误差项的方差</h3>
<p>我们构造一个估计量：<br>
$$<br>
\hat{\sigma^2}=\frac{\sum_{i=1}^n{\hat{u_i}}^2}{n-k-1}<br>
$$<br>
$n-k-1$为残差变动的<strong>自由度</strong>，即残差可以自由取值的个数，即当我们给定残差中的$n-k-1$个，余下的$k+1$个便是已知的，$k+1$个限制来自于最小二乘法时$k+1$个限制条件。</p>
<h3 id="定理3-3-sigma-2-的无偏估计">定理3.3 $\sigma^2$的无偏估计</h3>
<p>由假设$MLR.1-MLR.5$，我们有：<br>
$$<br>
E(\hat{\sigma^2})=\sigma^2<br>
$$</p>
<h5 id="证明：-2">证明：</h5>
<p>矩阵证明，暂时略，后续补。</p>
<p>$\hat{\sigma}$ 称为<strong>回归标准误</strong>（$standard\ error\ of\ the\ regression $）,简称 $ SER $，是误差项标准差的估计值。</p>
<p>$\hat{\beta_j}$的<strong>标准差</strong>（$standard\ deviation $）为：<br>
$$<br>
sd(\hat{\beta_j})=\sqrt{Var(\hat{\beta_j})}=<br>
\frac{\sigma}{\sqrt{SST_j(1-R_j^2)}}<br>
$$<br>
由于我们无法获得$\sigma$的真实值，故我们需要使用估计值$\hat{\sigma}$进行替换，则：</p>
<p>$\hat{\beta_j}$的<strong>标准误</strong>($standard\ error$)为：<br>
$$<br>
se(\hat{\beta_j})=\sqrt{\hat{Var}(\hat{\beta_j})}=<br>
\frac{\hat{\sigma}}{\sqrt{SST_j(1-R_j^2)}}<br>
$$<br>
标准误是一个<strong>随机变量</strong>，来源于样本，当样本确定时，标准误也随之确定。</p>
<p>值得注意的是，标准误的依赖于$Var(\hat{\beta_j})$的公式，而该公式又依赖与同方差假定$MLR.5$。所以如果误差出现异方差性，不会导致$\hat{\beta_j}$的偏误，却会导致对$Var(\hat{\beta_j})$的错误估计。</p>
<p>我们可以对标准误进行变形，得到：<br>
$$<br>
se(\hat{\beta_j})=\frac{\hat{\sigma}}{\sqrt{n}\ sd(x_j)\sqrt{(1-R_j^2)}}<br>
$$<br>
其中，$sd(x_j)=\sqrt{n^{-1}\sum_{i=1}^n(x_{ij}-\bar{x}_j)^2}$，是样本标准差。</p>
<p>$se(\hat{\beta_j})$中的各部分都随$n$的变动而变动，但是$n$越来越大时，除$\sqrt{n}$外各部分均会趋于常数。由此我们知道，标准误大致以$1/ \sqrt{n} $的速率收敛到0。</p>
<h3 id="OLS-的有效性：高斯-马尔科夫定理（-The-Gauss-Markov-Theorem-）">$OLS$的有效性：高斯-马尔科夫定理（$The\ Gauss-Markov\ Theorem$）</h3>
<p>我们需要判断普通最小二乘法（$OLS$）是不是好的，方法是与其他估计值进行比较。我们在比较$OLS$和其他方法估计值时，我们只比较<strong>线性估计值</strong>，即：<br>
$$<br>
\tilde{\beta_j}=\sum_{i=1}^n{\omega_{ij}y_i}<br>
$$<br>
其中，$w_{ij}$是自变量$x$的函数。</p>
<h3 id="定理3-4">定理3.4</h3>
<p>在假定$MLR.1-MLR.5$下，$\hat{\beta_0},\hat{\beta_1},…\hat{\beta_k}$是$\beta_0,\beta_1,…,\beta_k$的<strong>最优线性无偏估计量</strong>($BLUEs$)  ($Best\ Linear\ Unbiased\ Estimators$)</p>
<p>即，在<strong>所有线性无偏估计值</strong>里面，$OLS$的<strong>方差是最小的</strong>（因为方差的具体值是随样本变化而变化的，故这里方差最小值的是不管样本如何变化$Var(\hat{\beta_j})&lt;Var(\tilde\beta_j)$恒成立）。该定理说明了使用$OLS$估计多元回归模型的合理性。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="sdsfsf">Toby_</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2023/10/07/%E8%AE%A1%E9%87%8F%E7%BB%8F%E6%B5%8E%E5%AD%A64/">http://example.com/2023/10/07/%E8%AE%A1%E9%87%8F%E7%BB%8F%E6%B5%8E%E5%AD%A64/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">Toby_'s   Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://s2.loli.net/2023/10/13/d18EbiWQkAPCpIB.webp" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>赞助</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.jpg" target="_blank"><img class="post-qr-code-img" src="/img/wechat.jpg" alt="求求富哥打赏~QwQ"/></a><div class="post-qr-code-desc">求求富哥打赏~QwQ</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/09/27/%E6%82%84%E6%82%84%E8%AF%9D/" title="【慎入！！！】一些悄悄话~"><img class="cover" src="https://s2.loli.net/2023/09/27/9jo2Xvi1DzRETK4.webp" onerror="onerror=null;src='/img/%E8%83%8C%E6%99%AF%E5%9B%BE2.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">【慎入！！！】一些悄悄话~</div></div></a></div><div class="next-post pull-right"><a href="/2023/10/10/%E9%9A%8F%E6%9C%BA%E5%88%86%E6%9E%904/" title="【随机分析（四）】随机过程初探"><img class="cover" src="https://s2.loli.net/2023/10/13/8dDUk6o179MzcyT.webp" onerror="onerror=null;src='/img/%E8%83%8C%E6%99%AF%E5%9B%BE2.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">【随机分析（四）】随机过程初探</div></div></a></div></nav><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="disqus_thread"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Toby_</div><div class="author-info__description">蓬门今始为君开~</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">31</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Tooooooooooby"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Tooooooooooby" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:1098919940@qq.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">开心最重要！！！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E5%85%83%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.</span> <span class="toc-text">多元回归模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Example%EF%BC%9A"><span class="toc-number">2.</span> <span class="toc-text">Example：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E5%85%83%E5%9B%9E%E5%BD%92%E6%96%B9%E7%A8%8B%E7%9A%84%E6%8E%A8%E5%AF%BC"><span class="toc-number">3.</span> <span class="toc-text">多元回归方程的推导</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E5%80%BC%E7%89%B9%E5%BE%81%EF%BC%9A"><span class="toc-number">4.</span> <span class="toc-text">数值特征：</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A0%B7%E6%9C%AC%E5%9D%87%E5%80%BC%E7%82%B9%E5%9C%A8%E5%9B%9E%E5%BD%92%E7%BA%BF%E4%B8%8A"><span class="toc-number">4.1.</span> <span class="toc-text">样本均值点在回归线上</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%AF%8F%E4%B8%AA%E8%87%AA%E5%8F%98%E9%87%8F%E5%92%8COLS%E6%AE%8B%E5%B7%AE%E4%B9%8B%E9%97%B4%E7%9A%84%E6%A0%B7%E6%9C%AC%E5%8D%8F%E6%96%B9%E5%B7%AE%E4%B8%BA%E9%9B%B6"><span class="toc-number">4.2.</span> <span class="toc-text">每个自变量和OLS残差之间的样本协方差为零</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%AB%98%E7%BA%A7%E8%AE%A1%E9%87%8F%E7%BB%93%E6%9E%9C"><span class="toc-number">4.3.</span> <span class="toc-text">*高级计量结果</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E5%A4%9A%E5%85%83%E5%9B%9E%E5%BD%92%E6%8E%92%E9%99%A4%E5%85%B6%E4%BB%96%E5%8F%98%E9%87%8F%E7%9A%84%E8%A7%A3%E9%87%8A"><span class="toc-number">5.</span> <span class="toc-text">对多元回归排除其他变量的解释</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%AF%81%E6%98%8E%EF%BC%9A"><span class="toc-number">5.0.1.</span> <span class="toc-text">证明：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%90%86%E8%A7%A3"><span class="toc-number">5.0.2.</span> <span class="toc-text">理解:</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8B%9F%E5%90%88%E4%BC%98%E5%BA%A6-R-2"><span class="toc-number">6.</span> <span class="toc-text">拟合优度$R^2$</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#OLS-%E4%BC%B0%E8%AE%A1%E9%87%8F%E7%9A%84%E6%9C%9F%E6%9C%9B%E5%80%BC"><span class="toc-number"></span> <span class="toc-text">$OLS$估计量的期望值</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%8F%E5%85%B8%E5%81%87%E8%AE%BE%E6%9D%A1%E4%BB%B6"><span class="toc-number">1.</span> <span class="toc-text">经典假设条件</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Assumption-MLR-1-%E7%BA%BF%E6%80%A7%E4%BA%8E%E5%8F%82%E6%95%B0"><span class="toc-number">1.1.</span> <span class="toc-text">Assumption MLR.1 (线性于参数)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Assumption-MLR-2-%E9%9A%8F%E6%9C%BA%E6%8A%BD%E6%A0%B7"><span class="toc-number">1.2.</span> <span class="toc-text">Assumption MLR.2 (随机抽样)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Assumption-MLR-3-No-perfect-collinearity%E4%B8%8D%E5%AD%98%E5%9C%A8%E5%AE%8C%E5%85%A8%E5%85%B1%E7%BA%BF%E6%80%A7"><span class="toc-number">1.3.</span> <span class="toc-text">Assumption MLR.3  (No perfect collinearity不存在完全共线性)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Assumption-MLR-4-%E6%9D%A1%E4%BB%B6%E5%9D%87%E5%80%BC%E4%B8%BA%E9%9B%B6"><span class="toc-number">1.4.</span> <span class="toc-text">Assumption MLR.4(条件均值为零)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E7%90%863-1-%E6%97%A0%E5%81%8F%E6%80%A7"><span class="toc-number">2.</span> <span class="toc-text">定理3.1 无偏性</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%88%9D%E7%AD%89%E4%BB%A3%E6%95%B0%E8%AF%81%E6%98%8E%EF%BC%9A"><span class="toc-number">2.0.1.</span> <span class="toc-text">初等代数证明：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%9F%A9%E9%98%B5%E8%AF%81%E6%98%8E%EF%BC%9A"><span class="toc-number">2.0.2.</span> <span class="toc-text">矩阵证明：</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%93%AA%E4%BA%9B%E6%83%85%E5%86%B5%E4%BC%9A%E5%BD%B1%E5%93%8D%E6%88%91%E4%BB%AC%E8%8E%B7%E5%BE%97%E6%97%A0%E5%81%8F%E4%BC%B0%E8%AE%A1%E5%80%BC%EF%BC%9F"><span class="toc-number">3.</span> <span class="toc-text">哪些情况会影响我们获得无偏估计值？</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%81%97%E6%BC%8F%E5%8F%98%E9%87%8F%EF%BC%9A"><span class="toc-number">3.1.</span> <span class="toc-text">遗漏变量：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#OLS-%E7%BB%9F%E8%AE%A1%E9%87%8F%E7%9A%84%E6%96%B9%E5%B7%AE"><span class="toc-number">4.</span> <span class="toc-text">$OLS$统计量的方差</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Assumption-MLR-5-%E5%90%8C%E6%96%B9%E5%B7%AE%E6%80%A7"><span class="toc-number">4.1.</span> <span class="toc-text">Assumption MLR.5 (同方差性)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E7%90%863-2-OLS-%E6%96%9C%E7%8E%87%E4%BC%B0%E8%AE%A1%E9%87%8F%E7%9A%84%E6%8A%BD%E6%A0%B7%E6%96%B9%E5%B7%AE"><span class="toc-number">5.</span> <span class="toc-text">定理3.2  $OLS$斜率估计量的抽样方差</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%AF%81%E6%98%8E"><span class="toc-number">5.0.1.</span> <span class="toc-text">证明</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E9%87%8D%E5%85%B1%E7%BA%BF%E6%80%A7"><span class="toc-number">6.</span> <span class="toc-text">多重共线性</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3%E5%A4%9A%E9%87%8D%E5%85%B1%E7%BA%BF%E6%80%A7%E7%9A%84%E6%96%B9%E6%B3%95"><span class="toc-number">6.1.</span> <span class="toc-text">解决多重共线性的方法</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%AF%E8%AE%BE%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E6%96%B9%E5%B7%AE"><span class="toc-number">7.</span> <span class="toc-text">误设模型中的方差</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%B0%E8%AE%A1%E8%AF%AF%E5%B7%AE%E9%A1%B9%E7%9A%84%E6%96%B9%E5%B7%AE"><span class="toc-number">8.</span> <span class="toc-text">估计误差项的方差</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E7%90%863-3-sigma-2-%E7%9A%84%E6%97%A0%E5%81%8F%E4%BC%B0%E8%AE%A1"><span class="toc-number">9.</span> <span class="toc-text">定理3.3 $\sigma^2$的无偏估计</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%AF%81%E6%98%8E%EF%BC%9A-2"><span class="toc-number">9.0.1.</span> <span class="toc-text">证明：</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#OLS-%E7%9A%84%E6%9C%89%E6%95%88%E6%80%A7%EF%BC%9A%E9%AB%98%E6%96%AF-%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E5%AE%9A%E7%90%86%EF%BC%88-The-Gauss-Markov-Theorem-%EF%BC%89"><span class="toc-number">10.</span> <span class="toc-text">$OLS$的有效性：高斯-马尔科夫定理（$The\ Gauss-Markov\ Theorem$）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E7%90%863-4"><span class="toc-number">11.</span> <span class="toc-text">定理3.4</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/01/15/%E9%87%8F%E5%8C%96%E6%8A%95%E8%B5%84%E4%BD%9C%E4%B8%9A4/" title="量化投资第四次作业——ETF策略"><img src="https://s2.loli.net/2024/01/15/5sWkBq8hLjyvIiH.png" onerror="this.onerror=null;this.src='/img/%E8%83%8C%E6%99%AF%E5%9B%BE2.jpg'" alt="量化投资第四次作业——ETF策略"/></a><div class="content"><a class="title" href="/2024/01/15/%E9%87%8F%E5%8C%96%E6%8A%95%E8%B5%84%E4%BD%9C%E4%B8%9A4/" title="量化投资第四次作业——ETF策略">量化投资第四次作业——ETF策略</a><time datetime="2024-01-15T06:49:41.643Z" title="发表于 2024-01-15 14:49:41">2024-01-15</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/12/25/%E9%9A%8F%E6%9C%BA%E5%88%86%E6%9E%9011/" title="【随机分析（十一）】BS期权定价公式"><img src="https://s2.loli.net/2023/12/25/ezIZGx7kg1fcbma.png" onerror="this.onerror=null;this.src='/img/%E8%83%8C%E6%99%AF%E5%9B%BE2.jpg'" alt="【随机分析（十一）】BS期权定价公式"/></a><div class="content"><a class="title" href="/2023/12/25/%E9%9A%8F%E6%9C%BA%E5%88%86%E6%9E%9011/" title="【随机分析（十一）】BS期权定价公式">【随机分析（十一）】BS期权定价公式</a><time datetime="2023-12-25T04:13:32.674Z" title="发表于 2023-12-25 12:13:32">2023-12-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/12/24/%E9%9A%8F%E6%9C%BA%E5%88%86%E6%9E%9010/" title="【随机分析（十）】伊藤公式与随机微分方程"><img src="https://s2.loli.net/2023/12/25/P8TvAj1rpSsxdIW.png" onerror="this.onerror=null;this.src='/img/%E8%83%8C%E6%99%AF%E5%9B%BE2.jpg'" alt="【随机分析（十）】伊藤公式与随机微分方程"/></a><div class="content"><a class="title" href="/2023/12/24/%E9%9A%8F%E6%9C%BA%E5%88%86%E6%9E%9010/" title="【随机分析（十）】伊藤公式与随机微分方程">【随机分析（十）】伊藤公式与随机微分方程</a><time datetime="2023-12-24T07:24:41.041Z" title="发表于 2023-12-24 15:24:41">2023-12-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/12/23/%E9%9A%8F%E6%9C%BA%E5%88%86%E6%9E%909/" title="【随机分析（九）】随机积分"><img src="https://s2.loli.net/2023/12/25/qmBxgAdMciKIu67.png" onerror="this.onerror=null;this.src='/img/%E8%83%8C%E6%99%AF%E5%9B%BE2.jpg'" alt="【随机分析（九）】随机积分"/></a><div class="content"><a class="title" href="/2023/12/23/%E9%9A%8F%E6%9C%BA%E5%88%86%E6%9E%909/" title="【随机分析（九）】随机积分">【随机分析（九）】随机积分</a><time datetime="2023-12-23T11:41:15.052Z" title="发表于 2023-12-23 19:41:15">2023-12-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/12/14/%E9%87%8F%E5%8C%96%E6%8A%95%E8%B5%84%E4%BD%9C%E4%B8%9A3/" title="量化投资第三次作业——多因子选股策略"><img src="https://s2.loli.net/2024/01/15/jRu8Va1SJ5sgUWY.png" onerror="this.onerror=null;this.src='/img/%E8%83%8C%E6%99%AF%E5%9B%BE2.jpg'" alt="量化投资第三次作业——多因子选股策略"/></a><div class="content"><a class="title" href="/2023/12/14/%E9%87%8F%E5%8C%96%E6%8A%95%E8%B5%84%E4%BD%9C%E4%B8%9A3/" title="量化投资第三次作业——多因子选股策略">量化投资第三次作业——多因子选股策略</a><time datetime="2023-12-14T04:04:17.052Z" title="发表于 2023-12-14 12:04:17">2023-12-14</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://s2.loli.net/2023/10/13/d18EbiWQkAPCpIB.webp')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By Toby_</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script><script>(() => {
  const disqus_config = function () {
    this.page.url = 'http://example.com/2023/10/07/%E8%AE%A1%E9%87%8F%E7%BB%8F%E6%B5%8E%E5%AD%A64/'
    this.page.identifier = '/2023/10/07/%E8%AE%A1%E9%87%8F%E7%BB%8F%E6%B5%8E%E5%AD%A64/'
    this.page.title = '【计量经济学（四）】多元回归分析：估计'
  }

  const disqusReset = () => {
    window.DISQUS && window.DISQUS.reset({
      reload: true,
      config: disqus_config
    })
  }

  btf.addGlobalFn('themeChange', disqusReset, 'disqus')

  const loadDisqus = () =>{
    if (window.DISQUS) disqusReset()
    else {
      const script = document.createElement('script')
      script.src = 'https://tobyblog-1.disqus.com/embed.js'
      script.setAttribute('data-timestamp', +new Date())
      document.head.appendChild(script)
    }
  }

  const getCount = async() => {
    try {
      const eleGroup = document.querySelector('#post-meta .disqus-comment-count')
      if (!eleGroup) return
      const cleanedLinks = eleGroup.href.replace(/#post-comment$/, '')

      const res = await fetch(`https://disqus.com/api/3.0/threads/set.json?forum=tobyblog-1&api_key=&thread:link=${cleanedLinks}`,{
        method: 'GET'
      })
      const result = await res.json()

      const count = result.response.length ? result.response[0].posts : 0
      eleGroup.textContent = count
    } catch (err) {
      console.error(err)
    }
  }

  if ('Disqus' === 'Disqus' || !true) {
    if (true) btf.loadComment(document.getElementById('disqus_thread'), loadDisqus)
    else {
      loadDisqus()
      GLOBAL_CONFIG_SITE.isPost && getCount()
    }
  } else {
    window.loadOtherComment = loadDisqus
  }
})()</script></div><script>window.addEventListener('load', () => {
  const changeContent = (content) => {
    if (content === '') return content

    content = content.replace(/<img.*?src="(.*?)"?[^\>]+>/ig, '[图片]') // replace image link
    content = content.replace(/<a[^>]+?href=["']?([^"']+)["']?[^>]*>([^<]+)<\/a>/gi, '[链接]') // replace url
    content = content.replace(/<code>.*?<\/code>/gi, '[代码]') // replace code
    content = content.replace(/<[^>]+>/g,"") // remove html tag

    if (content.length > 150) {
      content = content.substring(0,150) + '...'
    }
    return content
  }

  const getComment = () => {
    fetch('https://disqus.com/api/3.0/forums/listPosts.json?forum=tobyblog-1&related=thread&limit=6&api_key=')
      .then(response => response.json())
      .then(data => {
        const disqusArray = data.response.map(item => {
          return {
            'avatar': item.author.avatar.cache,
            'content': changeContent(item.message),
            'nick': item.author.name,
            'url': item.url,
            'date': item.createdAt
          }
        })

        saveToLocal.set('disqus-newest-comments', JSON.stringify(disqusArray), 10/(60*24))
        generateHtml(disqusArray)
      }).catch(e => {
        const $dom = document.querySelector('#card-newest-comments .aside-list')
        $dom.textContent= "无法获取评论，请确认相关配置是否正确"
      })
  }

  const generateHtml = array => {
    let result = ''

    if (array.length) {
      for (let i = 0; i < array.length; i++) {
        result += '<div class=\'aside-list-item\'>'

        if (true) {
          const name = 'src'
          result += `<a href='${array[i].url}' class='thumbnail'><img ${name}='${array[i].avatar}' alt='${array[i].nick}'></a>`
        }
        
        result += `<div class='content'>
        <a class='comment' href='${array[i].url}' title='${array[i].content}'>${array[i].content}</a>
        <div class='name'><span>${array[i].nick}</span><time> / ${btf.diffDate(array[i].date, true)}</time></div>
        </div></div>`
      }
    } else {
      result += '没有评论'
    }

    let $dom = document.querySelector('#card-newest-comments .aside-list')
    $dom.innerHTML= result
    window.lazyLoadInstance && window.lazyLoadInstance.update()
    window.pjax && window.pjax.refresh($dom)
  }

  const newestCommentInit = () => {
    if (document.querySelector('#card-newest-comments .aside-list')) {
      const data = saveToLocal.get('disqus-newest-comments')
      if (data) {
        generateHtml(JSON.parse(data))
      } else {
        getComment()
      }
    }
  }

  newestCommentInit()
  document.addEventListener('pjax:complete', newestCommentInit)
})</script><div class="aplayer no-destroy" data-id="8729085683" data-server="netease" data-type="playlist" data-fixed="true" data-mini="true" data-listFolded="false" data-order="random" data-preload="none" data-autoplay="false" muted></div><script id="canvas_nest" defer="defer" color="255,255,255" opacity="0.810975" zIndex="-1" count="199" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-show-text.min.js" data-mobile="false" data-text="来者如临高山 往者以观逝水,今朝若是同淋雪 此生也算共白头,满目山河空念远 落花风雨更伤春 不如怜取眼前人,我是江南第一燕 为衔春色上云梢,志之所趋 无远弗届 穷山距海 不能限也,应是天仙狂醉 乱把白云揉碎,欲买桂花同载酒 终不似 少年游,休对故人思故国 且将新火试新茶 诗酒趁年华,何须浅碧深红色 自是花中第一流,当时明月在 曾照彩云归,最是人间留不住 朱颜辞镜花辞树,醉后不知天在水 满船清梦压星河,纸屏石枕竹方床 手倦抛书午梦长,晓看天色暮看云 行也思君 坐也思君,梦里不知身是客 一晌贪欢,我见青山多妩媚 料青山见我应如是,一川烟草 满城风絮 梅子黄时雨,人生若只如初见 何事秋风悲画扇,花自飘零水自流 一种相思 两处闲愁,竹杖芒鞋轻胜马，谁怕？一蓑烟雨任平生,仰天大笑出门去，我辈岂是蓬蒿人,须知少时凌云志，曾许人间第一流,山有木兮木有枝，心悦君兮君不知,凭君莫话封侯事，一将功成万骨枯,两岸猿声啼不住，轻舟已过万重山" data-fontsize="18px" data-random="true" async="async"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener
  btf.removeGlobalFnEvent('pjax')
  btf.removeGlobalFnEvent('themeChange')

  document.getElementById('rightside').classList.remove('rightside-show')
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', e => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script></div></body></html>